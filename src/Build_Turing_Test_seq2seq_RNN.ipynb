{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and Evaluate Sequence-to-Sequence (Encoder-Decoder) RNN to Classify Responses as Chatbot vs. Human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, GRU\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load training data\n",
    "file_name = 'data/x_r_full_tur4_shuf.pkl'\n",
    "file_obj = open(file_name,'rb') \n",
    "x_vec = pickle.load(file_obj)   \n",
    "file_obj.close()\n",
    "file_name = 'data/y_in_tur4_shuf.pkl'\n",
    "file_obj = open(file_name,'rb') \n",
    "y_in_vec = pickle.load(file_obj)   \n",
    "file_obj.close()\n",
    "file_name = 'data/y_tar_tur4_shuf.pkl'\n",
    "file_obj = open(file_name,'rb') \n",
    "y_tar_vec = pickle.load(file_obj)   \n",
    "file_obj.close()\n",
    "file_name = 'data/wrd_vec4.pkl'\n",
    "file_obj = open(file_name,'rb') \n",
    "wrd_vec = pickle.load(file_obj)   \n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# length of GLoVe word encoding vectors\n",
    "num_encoder_tokens = 50\n",
    "num_decoder_tokens = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.asarray(x_vec, dtype=float)\n",
    "decoder_input_data = np.asarray(y_in_vec, dtype=float)\n",
    "decoder_target_data = np.asarray(y_tar_vec, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_vec, y_in_vec, y_tar_vec, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# by design, max dialog is 60 words; decoder also has appended start/stop word for input/target sequences\n",
    "max_encoder_seq_length = 60\n",
    "max_decoder_seq_length = 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "latent_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 40000\n",
      "Number of unique input tokens: 50\n",
      "Number of unique output tokens: 50\n",
      "Max sequence length for inputs: 60\n",
      "Max sequence length for outputs: 61\n",
      "Batch size: 64\n",
      "Number of epochs: 3\n",
      "Hidden layer size: 256\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(encoder_input_data))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "print('Batch size:',batch_size)\n",
    "print('Number of epochs:',epochs)\n",
    "print('Hidden layer size:',latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_token_index = wrd_vec\n",
    "target_token_index = {'hum':[0,1], 'bot':[1,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoder model\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)  # LSTM memory for hidden layer\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# Only encoder states are relevant to seq2seq model\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder model conditioned on final encoder state\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=False, return_state=True)  # LSTM memory for hidden layer\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(2, activation='softmax')  # 2x softmax outputs for binary classification human/bot channel\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign structure to a model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/3\n",
      "32000/32000 [==============================] - 507s - loss: 0.0398 - acc: 0.9851 - val_loss: 0.0386 - val_acc: 0.9926\n",
      "Epoch 2/3\n",
      "32000/32000 [==============================] - 513s - loss: 0.0255 - acc: 0.9957 - val_loss: 0.0162 - val_acc: 0.9975\n",
      "Epoch 3/3\n",
      "32000/32000 [==============================] - 499s - loss: 0.0171 - acc: 0.9973 - val_loss: 0.0126 - val_acc: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c89481bd30>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SGD using Adam optimization and cross-entropy loss \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size, epochs=epochs, validation_split = 0.2)\n",
    "# based on trial # epochs, validation loss profile suggests early stopping at 3 epochs to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del encoder_input_data, decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load test data\n",
    "file_name = 'data/x_r_full_ts_tur4_shuf.pkl'\n",
    "file_obj = open(file_name,'rb') \n",
    "x_vec = pickle.load(file_obj)   \n",
    "file_obj.close()\n",
    "file_name = 'data/y_in_ts_tur4_shuf.pkl'\n",
    "file_obj = open(file_name,'rb') \n",
    "y_in_vec = pickle.load(file_obj)   \n",
    "file_obj.close()\n",
    "file_name = 'data/y_tar_ts_tur4_shuf.pkl'\n",
    "file_obj = open(file_name,'rb') \n",
    "y_tar_vec = pickle.load(file_obj)   \n",
    "file_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.asarray(x_vec, dtype=float)\n",
    "decoder_input_data = np.asarray(y_in_vec, dtype=float)\n",
    "decoder_target_data = np.asarray(y_tar_vec, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del x_vec, y_in_vec, y_tar_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 210s   \n"
     ]
    }
   ],
   "source": [
    "turing_out = model.predict([encoder_input_data, decoder_input_data])\n",
    "turing_score = model.evaluate([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turing loss performance: 0.012\n",
      "Turing acc performance:  0.998\n"
     ]
    }
   ],
   "source": [
    "print('Turing loss performance: {:4.3f}'.format(turing_score[0]))\n",
    "print('Turing acc performance: {:6.3f}'.format(turing_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_class = decoder_target_data[:,1]\n",
    "y_pred_class = []\n",
    "for i in range(len(turing_out)):\n",
    "    y_pred_class.append(round(turing_out[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate metrics: confusion metrics, recall, precision, F1 score\n",
    "confusion_turing = metrics.confusion_matrix(y_test_class, y_pred_class)\n",
    "recall_turing = metrics.recall_score(y_test_class, y_pred_class)\n",
    "precision_turing = metrics.precision_score(y_test_class, y_pred_class)\n",
    "F1_turing = metrics.f1_score(y_test_class, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20020     0]\n",
      " [   70 19910]]\n",
      "\n",
      "Turing recall:    0.996\n",
      "Turing precision: 1.000\n",
      "Turing F1 score:  0.998\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "print(confusion_turing)\n",
    "print()\n",
    "print('Turing recall: {:8.3f}'.format(recall_turing))\n",
    "print('Turing precision: {:5.3f}'.format(precision_turing))\n",
    "print('Turing F1 score: {:6.3f}'.format(F1_turing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq chatbot detection shows very strong performance characteristics for this data.  The present bot data does not reflect expected reality, but as a proof of concept the process suggests viability of the method"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
